# Nametag - Remember Everyone with G1 Smart Glasses# Nametag - Remember Everyone with G1 Smart Glasses# Nametag - Remember Everyone with G1 Smart Glasses



A MentraOS cloud app for Even Realities G1 smart glasses that automatically recognizes people by voice and displays contextual conversation history‚Äîall through audio-only interaction.



## FeaturesA MentraOS cloud app for Even Realities G1 smart glasses that automatically recognizes people by voice and displays contextual conversation history‚Äîall through audio-only interaction.



### Voice Biometric Recognition

- Real-time speaker identification using OpenAI's voice recognition

- Automatically detects and remembers people by their voice## ‚ú® FeaturesA MentraOS cloud app for Even Realities G1 smart glasses that automatically recognizes people by voice and displays contextual conversation history‚Äîall through audio-only interaction.

- No manual tagging or camera required‚Äîaudio only



### Conversation Intelligence

- Contextual key points from past conversations displayed instantly### üé§ Voice Biometric Recognition

- Multi-conversation history tracking with timestamps

- Automatic conversation summarization and topic extraction- **Real-time speaker identification** using OpenAI's voice recognition

- Smart speaker ID replacement (names, not "Speaker A/B")

- Automatically detects and remembers people by their voice## ‚ú® Features## Features

### Smart Introductions

- Detects self-introductions ("I'm John", "My name is Sarah")- No manual tagging or camera required‚Äîaudio only

- Creates voice profiles automatically for future recognition

- Shows personalized greetings with last met time and conversation count



### Battery-Efficient UI### üí¨ Conversation Intelligence

- Minimal listening indicator (2-second refresh rate)

- Optimized for G1 display constraints (240 chars, 6-8 lines)- **Contextual key points** from past conversations displayed instantly### üé§ Voice Biometric Recognition- **Real-time Name Recognition**: Automatically detects when people introduce themselves

- Smart pause/resume when showing person information

- Multi-conversation history tracking with timestamps

## Architecture

- Automatic conversation summarization and topic extraction- **Real-time speaker identification** using OpenAI's voice recognition- **Conversation Memory**: Stores conversation summaries and topics

```

G1 Glasses Audio ‚Üí MentraOS ‚Üí Cloud App ‚Üí OpenAI GPT-4o ‚Üí Local File Storage- Smart speaker ID replacement (names, not "Speaker A/B")

```

- Automatically detects and remembers people by their voice- **Person Recognition**: Remembers people you've met before and shows their context

**Key Flow:**

1. Audio streamed from G1 microphone### üëã Smart Introductions

2. OpenAI transcribes and identifies speakers by voice

3. Names extracted from self-introductions- Detects self-introductions ("I'm John", "My name is Sarah")- No manual tagging or camera required‚Äîaudio only- **Audio-Only Interface**: Works entirely through voice with visual feedback on glasses

4. Conversation history retrieved and displayed

5. Context saved with key points for next meeting- Creates voice profiles automatically for future recognition



## Tech Stack- Shows personalized greetings with last met time and conversation count



- **Runtime**: Bun (TypeScript)

- **Framework**: MentraOS SDK

- **AI Models**: ### üîã Battery-Efficient UI### üí¨ Conversation Intelligence## Architecture

  - OpenAI `gpt-4o-mini` (name extraction, summarization)

  - OpenAI `gpt-4o-transcribe-diarize` (voice recognition)- Minimal listening indicator (2-second refresh rate)

- **Storage**: Local JSON file storage (`./data/memories.json`)

- **Development**: ngrok for local tunneling- Optimized for G1 display constraints (240 chars, 6-8 lines)- **Contextual key points** from past conversations displayed instantly



## Prerequisites- Smart pause/resume when showing person information



### Hardware- Multi-conversation history tracking with timestamps```

- Even Realities G1 smart glasses

- MentraOS mobile app## üèóÔ∏è Architecture



### Software- Automatic conversation summarization and topic extractionSmart Glasses ‚Üí MentraOS ‚Üí Cloud App ‚Üí OpenAI GPT-4o-mini (Name Extraction)

- [Bun](https://bun.sh) (recommended) or Node.js 18+

- [ngrok](https://ngrok.com) account with static domain```



### API KeysG1 Glasses Audio ‚Üí MentraOS ‚Üí Cloud App (this) ‚Üí OpenAI GPT-4o- Smart speaker ID replacement (names, not "Speaker A/B")                                     ‚Üí Memory MCP (Storage)

- **MentraOS API Key**: [console.mentra.glass](https://console.mentra.glass)

- **OpenAI API Key**: [platform.openai.com](https://platform.openai.com)                                                ‚Üí Local File Storage



## Quick Start```                                     ‚Üí AssemblyAI (Future: Speaker Diarization)



### 1. Clone and Install



```bash**Key Flow:**### üëã Smart Introductions```

git clone https://github.com/ThatChocolateGuy/nametag.git

cd nametag1. Audio streamed from G1 microphone

bun install

```2. OpenAI transcribes + identifies speakers by voice- Detects self-introductions ("I'm John", "My name is Sarah")



### 2. Configure Environment3. Names extracted from self-introductions



Copy `.env.example` to `.env` and add your keys:4. Conversation history retrieved and displayed- Creates voice profiles automatically for future recognition## Tech Stack



```env5. Context saved with key points for next meeting

PACKAGE_NAME=nem.codes.nametag

MENTRAOS_API_KEY=your_mentraos_api_key- Shows personalized greetings with last met time and conversation count

OPENAI_API_KEY=your_openai_api_key

OPENAI_MODEL=gpt-4o-mini## üõ†Ô∏è Tech Stack

PORT=3000

```- **Runtime**: Node.js 18+ with TypeScript



### 3. Start the App- **Runtime**: Bun (TypeScript)



```bash- **Framework**: MentraOS SDK### üîã Battery-Efficient UI- **Framework**: MentraOS SDK

bun run dev

```- **AI Models**: 



### 4. Expose with ngrok  - OpenAI `gpt-4o-mini` (name extraction, summarization)- Minimal listening indicator (2-second refresh rate)- **Name Extraction & Summarization**: OpenAI GPT-4o-mini



In a separate terminal:  - OpenAI `gpt-4o-transcribe-diarize` (voice recognition)



```bash- **Storage**: Local JSON file storage (`./data/memories.json`)- Optimized for G1 display constraints (240 chars, 6-8 lines)- **Memory Storage**: Memory MCP Server

ngrok http --domain=your-static-domain.ngrok-free.app 3000

```- **Development**: ngrok for local tunneling



### 5. Register in MentraOS Console- Smart pause/resume when showing person information- **Future Enhancement**: AssemblyAI for speaker diarization



1. Go to [console.mentra.glass](https://console.mentra.glass)## üìã Prerequisites

2. Create a new app with your package name

3. Set Public URL to your ngrok domain (no trailing slash)

4. Add **Microphone** permission

5. Save and install on your G1 glasses### Hardware



## Using Nametag- Even Realities G1 smart glasses## üèóÔ∏è Architecture## Prerequisites



1. **Start the app** on your glasses- MentraOS mobile app

2. You'll see a **listening indicator**: `[=  ]` animating

3. **When someone speaks**:

   - If they introduce themselves ‚Üí Name saved with voice profile

   - If voice recognized ‚Üí Shows name + last met + conversation context### Software

   - If unknown ‚Üí Speaker tracked as "A", "B", etc. until introduction

- [Bun](https://bun.sh) (recommended) or Node.js 18+```1. **Hardware**:

4. **Key Points Display Example**:

   ```- [ngrok](https://ngrok.com) account with static domain

   John ‚Ä¢ 3d ago ‚Ä¢ 5x

   G1 Glasses Audio ‚Üí MentraOS ‚Üí Cloud App (this) ‚Üí OpenAI GPT-4o   - Even Realities G1 smart glasses (or compatible MentraOS device)

   ‚Ä¢ Needs report by Friday

   ‚Ä¢ Budget approval pending### API Keys

   ‚Ä¢ Team meeting scheduled

   ```- **MentraOS API Key**: [console.mentra.glass](https://console.mentra.glass)                                                ‚Üí Local File Storage   - MentraOS mobile app installed



5. **End conversation** by closing the app- **OpenAI API Key**: [platform.openai.com](https://platform.openai.com)

   - Summary automatically saved

   - Key points extracted for next meeting```



## Documentation## üöÄ Quick Start



All detailed documentation is in the [`/docs`](./docs) folder:2. **Software**:



- [QUICKSTART.md](./docs/QUICKSTART.md) - Step-by-step setup guide### 1. Clone and Install

- [IMPLEMENTATION.md](./docs/IMPLEMENTATION.md) - Technical architecture details

- [TESTING_GUIDE.md](./docs/TESTING_GUIDE.md) - How to test the app**Key Flow:**   - Node.js 18 or higher

- [MODEL_SELECTION.md](./docs/MODEL_SELECTION.md) - OpenAI model configuration

- [STORAGE.md](./docs/STORAGE.md) - Data storage structure```bash

- [TROUBLESHOOTING_NGROK.md](./docs/TROUBLESHOOTING_NGROK.md) - Common ngrok issues

git clone https://github.com/ThatChocolateGuy/nametag.git1. Audio streamed from G1 microphone   - npm or bun

## Development

cd nametag

### File Structure

bun install2. OpenAI transcribes + identifies speakers by voice   - ngrok account (for local development)

```

nametag/```

‚îú‚îÄ‚îÄ src/

‚îÇ   ‚îú‚îÄ‚îÄ index.ts                      # Main app server3. Names extracted from self-introductions

‚îÇ   ‚îî‚îÄ‚îÄ services/

‚îÇ       ‚îú‚îÄ‚îÄ conversationManager.ts    # Conversation orchestration### 2. Configure Environment

‚îÇ       ‚îú‚îÄ‚îÄ nameExtractionService.ts  # OpenAI name extraction

‚îÇ       ‚îú‚îÄ‚îÄ openaiTranscriptionService.ts  # Voice recognition4. Conversation history retrieved and displayed3. **API Keys**:

‚îÇ       ‚îú‚îÄ‚îÄ fileStorageClient.ts      # Local storage

‚îÇ       ‚îî‚îÄ‚îÄ memoryClient.ts           # Legacy MCP interfaceCopy `.env.example` to `.env`:

‚îú‚îÄ‚îÄ data/

‚îÇ   ‚îî‚îÄ‚îÄ memories.json                 # Person database5. Context saved with key points for next meeting   - MentraOS API key (from [console.mentra.glass](https://console.mentra.glass))

‚îú‚îÄ‚îÄ docs/                             # Documentation

‚îî‚îÄ‚îÄ temp/                             # Temp audio files```bash

```

PACKAGE_NAME=nem.codes.nametag   - OpenAI API key (from [platform.openai.com](https://platform.openai.com))

### Key Design Patterns

MENTRAOS_API_KEY=your_mentraos_api_key

- **Dual Storage Strategy**: Uses local file storage (primary) with MCP server interface (legacy) for easy swapping

- **Service Dependency Injection**: ConversationManager orchestrates all services (storage, AI, transcription) with clean interfacesOPENAI_API_KEY=your_openai_api_key## üõ†Ô∏è Tech Stack   - AssemblyAI API key (from [assemblyai.com](https://assemblyai.com)) - Optional for POC

- **Voice Reference Storage**: 7-second audio clips stored as base64 for future voice matching by OpenAI

- **Speaker Identity Protection**: Once a speaker is identified in a session, that mapping persists to prevent misidentificationOPENAI_MODEL=gpt-4o-mini



## Cost EstimatePORT=3000   - Memory MCP Server URL (provided)



With OpenAI `gpt-4o-mini` (default):```

- **Name extraction**: ~$0.0001 per request

- **Conversation summary**: ~$0.001 per conversation- **Runtime**: Bun (TypeScript)

- **Voice transcription**: ~$0.002 per minute of audio

### 3. Start the App

**Typical daily usage** (10 conversations, 5 min each):

- ~$0.05/day = **~$1.50/month**- **Framework**: MentraOS SDK## Setup Instructions



See [MODEL_SELECTION.md](./docs/MODEL_SELECTION.md) for cost/performance details.```bash



## Contributingbun run dev- **AI Models**: 



This is a personal project, but feel free to:```

- Report issues

- Suggest features  - OpenAI `gpt-4o-mini` (name extraction, summarization)### 1. Install Dependencies

- Fork and experiment!

### 4. Expose with ngrok

## License

  - OpenAI `gpt-4o-transcribe-diarize` (voice recognition)

MIT License - see [LICENSE](./LICENSE) file

In a separate terminal:

## Acknowledgments

- **Storage**: Local JSON file storage (`./data/memories.json`)**With Bun (Recommended):**

- **MentraOS Team** for the excellent SDK and G1 hardware

- **OpenAI** for powerful voice recognition and language models```bash

- **Even Realities** for the incredible G1 smart glasses

ngrok http --domain=your-static-domain.ngrok-free.app 3000- **Development**: ngrok for local tunneling```bash

## Support

```

- **Issues**: [GitHub Issues](https://github.com/ThatChocolateGuy/nametag/issues)

- **Docs**: Check the [`/docs`](./docs) foldercd smartglasses-memory-app

- **MentraOS**: [console.mentra.glass](https://console.mentra.glass)

### 5. Register in MentraOS Console

---

## üìã Prerequisitesbun install

**Built with ‚ù§Ô∏è for the G1 community**

1. Go to [console.mentra.glass](https://console.mentra.glass)

2. Create a new app with your package name```

3. Set Public URL to your ngrok domain (no trailing slash!)

4. Add **Microphone** permission### Hardware

5. Save and install on your G1 glasses

- Even Realities G1 smart glasses**Or with npm:**

## üì± Using Nametag

- MentraOS mobile app```bash

1. **Start the app** on your glasses

2. You'll see a **listening indicator**: `[=  ]` animatingnpm install

3. **When someone speaks**:

   - If they introduce themselves ‚Üí Name saved with voice profile### Software```

   - If voice recognized ‚Üí Shows name + last met + conversation context

   - If unknown ‚Üí Speaker tracked as "A", "B", etc. until introduction- [Bun](https://bun.sh) (recommended) or Node.js 18+



4. **Key Points Display**:- [ngrok](https://ngrok.com) account with static domain### 2. Configure Environment Variables

   ```

   John ‚Ä¢ 3d ago ‚Ä¢ 5x

   

   ‚Ä¢ Needs report by Friday### API Keys```bash

   ‚Ä¢ Budget approval pending

   ‚Ä¢ Team meeting scheduled- **MentraOS API Key**: [console.mentra.glass](https://console.mentra.glass)cp .env.example .env

   ```

- **OpenAI API Key**: [platform.openai.com](https://platform.openai.com)```

5. **End conversation** by closing the app

   - Summary automatically saved

   - Key points extracted for next meeting

## üöÄ Quick StartEdit `.env` with your credentials:

## üìñ Documentation



All detailed documentation is in the [`/docs`](./docs) folder:

### 1. Clone and Install```env

- **[QUICKSTART.md](./docs/QUICKSTART.md)** - Step-by-step setup guide

- **[IMPLEMENTATION.md](./docs/IMPLEMENTATION.md)** - Technical architecture detailsPORT=3000

- **[TESTING_GUIDE.md](./docs/TESTING_GUIDE.md)** - How to test the app

- **[MODEL_SELECTION.md](./docs/MODEL_SELECTION.md)** - OpenAI model configuration```bashPACKAGE_NAME=com.yourname.memoryapp

- **[STORAGE.md](./docs/STORAGE.md)** - Data storage structure

- **[TROUBLESHOOTING_NGROK.md](./docs/TROUBLESHOOTING_NGROK.md)** - Common ngrok issuesgit clone https://github.com/ThatChocolateGuy/nametag.gitMENTRAOS_API_KEY=your_mentraos_api_key_here



## üîß Developmentcd nametagASSEMBLYAI_API_KEY=your_assemblyai_api_key_here



### File Structurebun installANTHROPIC_API_KEY=your_anthropic_api_key_here



``````MEMORY_MCP_URL=https://memory.mcpgenerator.com/871b2b4d-418f-4c41-ad97-52d5b46c8772/sse

nametag/

‚îú‚îÄ‚îÄ src/```

‚îÇ   ‚îú‚îÄ‚îÄ index.ts                      # Main app server

‚îÇ   ‚îî‚îÄ‚îÄ services/### 2. Configure Environment

‚îÇ       ‚îú‚îÄ‚îÄ conversationManager.ts    # Conversation orchestration

‚îÇ       ‚îú‚îÄ‚îÄ nameExtractionService.ts  # OpenAI name extraction### 3. Set Up ngrok

‚îÇ       ‚îú‚îÄ‚îÄ openaiTranscriptionService.ts  # Voice recognition

‚îÇ       ‚îú‚îÄ‚îÄ fileStorageClient.ts      # Local storageCopy `.env.example` to `.env`:

‚îÇ       ‚îî‚îÄ‚îÄ memoryClient.ts           # Legacy MCP interface

‚îú‚îÄ‚îÄ data/1. Install ngrok:

‚îÇ   ‚îî‚îÄ‚îÄ memories.json                 # Person database

‚îú‚îÄ‚îÄ docs/                             # Documentation```bash   ```bash

‚îî‚îÄ‚îÄ temp/                             # Temp audio files

```PACKAGE_NAME=nem.codes.nametag   # Windows (with chocolatey)



### Key Design PatternsMENTRAOS_API_KEY=your_mentraos_api_key   choco install ngrok



**Dual Storage Strategy**: Uses local file storage (primary) with MCP server interface (legacy) for easy swapping.OPENAI_API_KEY=your_openai_api_key



**Service Dependency Injection**: ConversationManager orchestrates all services (storage, AI, transcription) with clean interfaces.OPENAI_MODEL=gpt-4o-mini   # macOS



**Voice Reference Storage**: 7-second audio clips stored as base64 for future voice matching by OpenAI.PORT=3000   brew install ngrok



**Speaker Identity Protection**: Once a speaker is identified in a session, that mapping persists to prevent misidentification.```



## üí∞ Cost Estimate   # Or download from https://ngrok.com/download



With OpenAI `gpt-4o-mini` (default):### 3. Start the App   ```

- **Name extraction**: ~$0.0001 per request

- **Conversation summary**: ~$0.001 per conversation

- **Voice transcription**: ~$0.002 per minute of audio

```bash2. Create a free ngrok account at [ngrok.com](https://ngrok.com)

**Typical daily usage** (10 conversations, 5 min each):

- ~$0.05/day = **~$1.50/month**bun run dev



See [MODEL_SELECTION.md](./docs/MODEL_SELECTION.md) for cost/performance details.```3. Get a static domain from [dashboard.ngrok.com](https://dashboard.ngrok.com)



## ü§ù Contributing



This is a personal project, but feel free to:### 4. Expose with ngrok### 4. Register App in MentraOS Console

- Report issues

- Suggest features

- Fork and experiment!

In a separate terminal:1. Go to [console.mentra.glass](https://console.mentra.glass)

## üìÑ License

2. Click "Sign In" (use same account as MentraOS app)

MIT License - see [LICENSE](./LICENSE) file

```bash3. Click "Create App"

## üôè Acknowledgments

ngrok http --domain=your-static-domain.ngrok-free.app 30004. Set package name (must match your .env file)

- **MentraOS Team** for the excellent SDK and G1 hardware

- **OpenAI** for powerful voice recognition and language models```5. Enter your ngrok static URL as "Public URL"

- **Even Realities** for the incredible G1 smart glasses

6. **Important**: Add "microphone" permission in app settings

## üìû Support

### 5. Register in MentraOS Console

- **Issues**: [GitHub Issues](https://github.com/ThatChocolateGuy/nametag/issues)

- **Docs**: Check the [`/docs`](./docs) folder### 5. Run the App

- **MentraOS**: [console.mentra.glass](https://console.mentra.glass)

1. Go to [console.mentra.glass](https://console.mentra.glass)

---

2. Create a new app with your package name**Terminal 1** - Start the app:

**Built with ‚ù§Ô∏è for the G1 community**

3. Set Public URL to your ngrok domain (no trailing slash!)

4. Add **Microphone** permission**With Bun (Recommended):**

5. Save and install on your G1 glasses```bash

bun run dev

## üì± Using Nametag```



1. **Start the app** on your glasses**Or with npm:**

2. You'll see a **listening indicator**: `[=  ]` animating```bash

3. **When someone speaks**:npm run dev

   - If they introduce themselves ‚Üí Name saved with voice profile```

   - If voice recognized ‚Üí Shows name + last met + conversation context

   - If unknown ‚Üí Speaker tracked as "A", "B", etc. until introduction**Terminal 2** - Expose with ngrok:

```bash

4. **Key Points Display**:ngrok http --url=<YOUR_NGROK_STATIC_URL> 3000

   ``````

   John ‚Ä¢ 3d ago ‚Ä¢ 5x

   ### 6. Connect Your Glasses

   ‚Ä¢ Needs report by Friday

   ‚Ä¢ Budget approval pending1. Open MentraOS app on your phone

   ‚Ä¢ Team meeting scheduled2. Find your app in the app list

   ```3. Launch it - the app will connect to your glasses

4. You should see "Nametag Ready!" on the glasses

5. **End conversation** by closing the app

   - Summary automatically saved## How It Works

   - Key points extracted for next meeting

### Name Detection

## üìñ Documentation

When someone says:

All detailed documentation is in the [`/docs`](./docs) folder:- "I'm John"

- "My name is Sarah"

- **[QUICKSTART.md](./docs/QUICKSTART.md)** - Step-by-step setup guide- "This is Alex"

- **[IMPLEMENTATION.md](./docs/IMPLEMENTATION.md)** - Technical architecture details- "Call me Mike"

- **[TESTING_GUIDE.md](./docs/TESTING_GUIDE.md)** - How to test the app

- **[MODEL_SELECTION.md](./docs/MODEL_SELECTION.md)** - OpenAI model configurationThe app will:

- **[STORAGE.md](./docs/STORAGE.md)** - Data storage structure1. Extract the name using OpenAI GPT-4o-mini

- **[TROUBLESHOOTING_NGROK.md](./docs/TROUBLESHOOTING_NGROK.md)** - Common ngrok issues2. Store it in memory with the MCP server

3. Show "Nice to meet you [Name]!" on glasses

## üîß Development

### Person Recognition

### File Structure

When you meet someone again:

```1. The app checks if the name exists in memory

nametag/2. Shows "Welcome back [Name]!"

‚îú‚îÄ‚îÄ src/3. Displays their last conversation summary

‚îÇ   ‚îú‚îÄ‚îÄ index.ts                      # Main app server4. Shows topics you previously discussed

‚îÇ   ‚îî‚îÄ‚îÄ services/

‚îÇ       ‚îú‚îÄ‚îÄ conversationManager.ts    # Conversation orchestration### Conversation Memory

‚îÇ       ‚îú‚îÄ‚îÄ nameExtractionService.ts  # OpenAI name extraction

‚îÇ       ‚îú‚îÄ‚îÄ openaiTranscriptionService.ts  # Voice recognitionAt the end of each session:

‚îÇ       ‚îú‚îÄ‚îÄ fileStorageClient.ts      # Local storage1. Generates a summary of the conversation

‚îÇ       ‚îî‚îÄ‚îÄ memoryClient.ts           # Legacy MCP interface2. Extracts key topics discussed

‚îú‚îÄ‚îÄ data/3. Updates each person's memory entry

‚îÇ   ‚îî‚îÄ‚îÄ memories.json                 # Person database4. Stores for future reference

‚îú‚îÄ‚îÄ docs/                             # Documentation

‚îî‚îÄ‚îÄ temp/                             # Temp audio files## Project Structure

```

```

### Key Design Patternssmartglasses-memory-app/

‚îú‚îÄ‚îÄ src/

**Dual Storage Strategy**: Uses local file storage (primary) with MCP server interface (legacy) for easy swapping.‚îÇ   ‚îú‚îÄ‚îÄ index.ts                    # Main application

‚îÇ   ‚îî‚îÄ‚îÄ services/

**Service Dependency Injection**: ConversationManager orchestrates all services (storage, AI, transcription) with clean interfaces.‚îÇ       ‚îú‚îÄ‚îÄ memoryClient.ts         # Memory MCP integration

‚îÇ       ‚îú‚îÄ‚îÄ nameExtractionService.ts # OpenAI GPT-4o-mini for names

**Voice Reference Storage**: 7-second audio clips stored as base64 for future voice matching by OpenAI.‚îÇ       ‚îú‚îÄ‚îÄ diarizationService.ts   # AssemblyAI (future use)

‚îÇ       ‚îî‚îÄ‚îÄ conversationManager.ts  # Orchestration logic

**Speaker Identity Protection**: Once a speaker is identified in a session, that mapping persists to prevent misidentification.‚îú‚îÄ‚îÄ package.json

‚îú‚îÄ‚îÄ tsconfig.json

## üí∞ Cost Estimate‚îú‚îÄ‚îÄ .env.example

‚îî‚îÄ‚îÄ README.md

With OpenAI `gpt-4o-mini` (default):```

- **Name extraction**: ~$0.0001 per request

- **Conversation summary**: ~$0.001 per conversation## API Usage & Costs

- **Voice transcription**: ~$0.002 per minute of audio

### OpenAI (GPT-4o-mini)

**Typical daily usage** (10 conversations, 5 min each):- **Model**: GPT-4o-mini

- ~$0.05/day = **~$1.50/month**- **Usage**: Name extraction + conversation summarization

- **Cost**: $0.150 per 1M input tokens, $0.600 per 1M output tokens

See [MODEL_SELECTION.md](./docs/MODEL_SELECTION.md) for cost/performance details.- **Per operation**: ~$0.0003 per name extraction, ~$0.001 per summary

- **Estimate**: < $0.20 for typical day of use (10x cheaper than Claude!)

## ü§ù Contributing

### AssemblyAI (Optional)

This is a personal project, but feel free to:- **Usage**: Speaker diarization (not used in POC)

- Report issues- **Cost**: $0.02/hour of audio

- Suggest features- **Note**: POC uses MentraOS built-in transcription

- Fork and experiment!

### Memory MCP Server

## üìÑ License- **Cost**: FREE (provided server)



MIT License - see [LICENSE](./LICENSE) file## Current Limitations (POC)



## üôè Acknowledgments1. **No True Speaker Diarization**: Uses MentraOS transcription without speaker separation

   - Everyone is labeled as "Speaker A"

- **MentraOS Team** for the excellent SDK and G1 hardware   - Future: Integrate AssemblyAI for multi-speaker support

- **OpenAI** for powerful voice recognition and language models

- **Even Realities** for the incredible G1 smart glasses2. **Name Detection Timing**: Checks every 30 seconds

   - Batches transcripts for efficiency

## üìû Support   - May have slight delay in recognition



- **Issues**: [GitHub Issues](https://github.com/ThatChocolateGuy/nametag/issues)3. **Single Session Memory**: Best for one-on-one or small group conversations

- **Docs**: Check the [`/docs`](./docs) folder

- **MentraOS**: [console.mentra.glass](https://console.mentra.glass)## Future Enhancements



---### Phase 2: True Speaker Diarization

- Capture raw audio from glasses microphone

**Built with ‚ù§Ô∏è for the G1 community**- Stream to AssemblyAI for real-time speaker separation

- Match speakers to stored voice profiles
- Automatic person identification without names

### Phase 3: Enhanced Memory
- Voice biometrics for speaker identification
- Cross-session conversation threading
- Smart reminders ("Ask John about his vacation")
- Integration with calendar/contacts

### Phase 4: Advanced Features
- Multi-language support
- Emotional tone analysis
- Action items extraction
- Integration with note-taking apps

## Troubleshooting

### App won't connect to glasses

1. Check ngrok is running and URL matches console
2. Verify package name matches in .env and console
3. Check microphone permission is enabled
4. Restart MentraOS mobile app

### Names not being detected

1. Check OpenAI API key is valid
2. Look at console logs for errors
3. Try explicit introductions: "My name is..."
4. Wait 30 seconds for processing interval

### Memory not persisting

1. Verify Memory MCP URL is correct
2. Check network connectivity
3. Look for errors in console logs
4. Test MCP server with curl

### Build errors

```bash
# Clean and reinstall
rm -rf node_modules package-lock.json
npm install

# Rebuild TypeScript
npm run build
```

## Development

### Build for Production

```bash
npm run build
npm start
```

### Code Structure

- **index.ts**: Main MentraOS app server
- **memoryClient.ts**: MCP server interface
- **nameExtractionService.ts**: OpenAI GPT-4o-mini integration
- **conversationManager.ts**: Business logic orchestration
- **diarizationService.ts**: AssemblyAI integration (prepared for future)

### Adding New Features

1. Add service in `src/services/`
2. Import and initialize in `index.ts` constructor
3. Use in `onSession` method for session-specific logic
4. Update this README with new capabilities

## Contributing

This is a proof-of-concept. Key areas for contribution:
- AssemblyAI integration for true speaker diarization
- Voice profile matching
- Better memory search/retrieval
- UI improvements for glasses display
- Multi-language support

## License

MIT

## Credits

Built with:
- [MentraOS](https://mentra.glass) - Smart glasses platform
- [OpenAI](https://openai.com) - AI name extraction (GPT-4o-mini)
- [AssemblyAI](https://assemblyai.com) - Speech recognition
- Memory MCP Server - Data persistence

## Support

For issues or questions:
- MentraOS: [Discord](https://discord.gg/mentra)
- This project: Create an issue on GitHub

---

**Note**: This is a proof-of-concept for demonstration purposes. For production use, implement proper error handling, security measures, and privacy protections for personal data.
